{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-39719dc0b80d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVariable\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mVar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0m_dl_flags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m __all__ += [name for name in dir(_C)\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "from torch import nn,optim\n",
    "from torch.autograd import Variable as Var \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch, torchvision\n",
    "from torch import nn,optim\n",
    "from torch.autograd import Variable as var\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:702: UserWarning: Duplicate names specified. This will raise an error in the future.\n",
      "  return _read(filepath_or_buffer, kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>imu_hand</th>\n",
       "      <th>imu_hand.1</th>\n",
       "      <th>imu_hand.2</th>\n",
       "      <th>imu_hand.3</th>\n",
       "      <th>imu_hand.4</th>\n",
       "      <th>imu_hand.5</th>\n",
       "      <th>imu_hand.6</th>\n",
       "      <th>...</th>\n",
       "      <th>IMU_ancle.7</th>\n",
       "      <th>IMU_ancle.8</th>\n",
       "      <th>IMU_ancle.9</th>\n",
       "      <th>IMU_ancle.10</th>\n",
       "      <th>IMU_ancle.11</th>\n",
       "      <th>IMU_ancle.12</th>\n",
       "      <th>IMU_ancle.13</th>\n",
       "      <th>IMU_ancle.14</th>\n",
       "      <th>IMU_ancle.15</th>\n",
       "      <th>IMU_ancle.16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>376412</th>\n",
       "      <td>3772.50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.5</td>\n",
       "      <td>2.02477</td>\n",
       "      <td>7.29553</td>\n",
       "      <td>5.74194</td>\n",
       "      <td>2.06573</td>\n",
       "      <td>6.57692</td>\n",
       "      <td>5.92695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048745</td>\n",
       "      <td>-0.008034</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>-58.8381</td>\n",
       "      <td>-36.2397</td>\n",
       "      <td>-11.0980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376413</th>\n",
       "      <td>3772.51</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.5</td>\n",
       "      <td>2.10836</td>\n",
       "      <td>7.86504</td>\n",
       "      <td>5.85674</td>\n",
       "      <td>2.08754</td>\n",
       "      <td>7.42244</td>\n",
       "      <td>5.87977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042113</td>\n",
       "      <td>0.024647</td>\n",
       "      <td>0.013375</td>\n",
       "      <td>-58.9537</td>\n",
       "      <td>-36.3379</td>\n",
       "      <td>-11.7170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376414</th>\n",
       "      <td>3772.52</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.5</td>\n",
       "      <td>2.07163</td>\n",
       "      <td>8.39581</td>\n",
       "      <td>5.77742</td>\n",
       "      <td>2.13833</td>\n",
       "      <td>8.05640</td>\n",
       "      <td>5.90853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014889</td>\n",
       "      <td>0.026009</td>\n",
       "      <td>0.025054</td>\n",
       "      <td>-59.1781</td>\n",
       "      <td>-35.8985</td>\n",
       "      <td>-10.9678</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376415</th>\n",
       "      <td>3772.53</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.5</td>\n",
       "      <td>2.19569</td>\n",
       "      <td>8.77634</td>\n",
       "      <td>6.00892</td>\n",
       "      <td>2.11251</td>\n",
       "      <td>8.53989</td>\n",
       "      <td>5.93770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047026</td>\n",
       "      <td>-0.035531</td>\n",
       "      <td>0.024640</td>\n",
       "      <td>-58.8299</td>\n",
       "      <td>-36.6845</td>\n",
       "      <td>-10.8553</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376416</th>\n",
       "      <td>3772.54</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.5</td>\n",
       "      <td>2.14774</td>\n",
       "      <td>8.66047</td>\n",
       "      <td>5.73918</td>\n",
       "      <td>2.15810</td>\n",
       "      <td>8.59995</td>\n",
       "      <td>5.92242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042585</td>\n",
       "      <td>0.017541</td>\n",
       "      <td>-0.037894</td>\n",
       "      <td>-59.1707</td>\n",
       "      <td>-36.7731</td>\n",
       "      <td>-11.5961</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_stamp  activity_id  heart_rate  imu_hand  imu_hand.1  imu_hand.2  \\\n",
       "376412     3772.50            0         NaN      30.5     2.02477     7.29553   \n",
       "376413     3772.51            0         NaN      30.5     2.10836     7.86504   \n",
       "376414     3772.52            0         NaN      30.5     2.07163     8.39581   \n",
       "376415     3772.53            0         NaN      30.5     2.19569     8.77634   \n",
       "376416     3772.54            0         NaN      30.5     2.14774     8.66047   \n",
       "\n",
       "        imu_hand.3  imu_hand.4  imu_hand.5  imu_hand.6  ...  IMU_ancle.7  \\\n",
       "376412     5.74194     2.06573     6.57692     5.92695  ...     0.048745   \n",
       "376413     5.85674     2.08754     7.42244     5.87977  ...     0.042113   \n",
       "376414     5.77742     2.13833     8.05640     5.90853  ...    -0.014889   \n",
       "376415     6.00892     2.11251     8.53989     5.93770  ...     0.047026   \n",
       "376416     5.73918     2.15810     8.59995     5.92242  ...     0.042585   \n",
       "\n",
       "        IMU_ancle.8  IMU_ancle.9  IMU_ancle.10  IMU_ancle.11  IMU_ancle.12  \\\n",
       "376412    -0.008034     0.018600      -58.8381      -36.2397      -11.0980   \n",
       "376413     0.024647     0.013375      -58.9537      -36.3379      -11.7170   \n",
       "376414     0.026009     0.025054      -59.1781      -35.8985      -10.9678   \n",
       "376415    -0.035531     0.024640      -58.8299      -36.6845      -10.8553   \n",
       "376416     0.017541    -0.037894      -59.1707      -36.7731      -11.5961   \n",
       "\n",
       "        IMU_ancle.13  IMU_ancle.14  IMU_ancle.15  IMU_ancle.16  \n",
       "376412           1.0           0.0           0.0           0.0  \n",
       "376413           1.0           0.0           0.0           0.0  \n",
       "376414           1.0           0.0           0.0           0.0  \n",
       "376415           1.0           0.0           0.0           0.0  \n",
       "376416           1.0           0.0           0.0           0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"time_stamp\",\"activity_id\",\"heart_rate\",\"imu_hand\",\"imu_hand\",\"imu_hand\",\"imu_hand\",\"imu_hand\",\"imu_hand\",\n",
    "               \"imu_hand\",\"imu_hand\",\"imu_hand\",\"imu_hand\",\"imu_hand\",\"imu_hand\",\"imu_hand\",\"imu_hand\",\"imu_hand\",\"imu_hand\"\n",
    "               ,\"imu_hand\",\"IMU_chest\",\"IMU_chest\",\"IMU_chest\",\"IMU_chest\",\"IMU_chest\",\"IMU_chest\",\"IMU_chest\",\"IMU_chest\"\n",
    "               ,\"IMU_chest\",\"IMU_chest\",\"IMU_chest\",\"IMU_chest\",\"IMU_chest\",\"IMU_chest\",\"IMU_chest\",\"IMU_chest\",\"IMU_chest\"\n",
    "               ,\"IMU_ancle\",\"IMU_ancle\",\"IMU_ancle\",\"IMU_ancle\",\"IMU_ancle\",\"IMU_ancle\",\"IMU_ancle\",\"IMU_ancle\",\"IMU_ancle\"\n",
    "               ,\"IMU_ancle\",\"IMU_ancle\",\"IMU_ancle\",\"IMU_ancle\",\"IMU_ancle\",\"IMU_ancle\",\"IMU_ancle\",\"IMU_ancle\"]\n",
    "subject1 = pd.read_csv(r'subject101.dat',sep = \" \",names = column_names)\n",
    "subject3 = pd.read_csv(r'subject104.dat',sep = \" \",names = column_names)\n",
    "\n",
    "subject1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376417, 54)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    " \n",
    "def series_to_supervised(data_full,type1, n_in=1, n_out=1, dropnan=True):\n",
    "    \n",
    "    data = data_full[type1].values\n",
    "\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        \n",
    "        agg.dropna(inplace=True)\n",
    "    rest = data_full[[\"time_stamp\",\"activity_id\"]][84:].values\n",
    "    agg.insert(0, \"activity_id\", rest[:,1])\n",
    "    agg.insert(0, \"time_stamp\", rest[:,0])\n",
    "       \n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series(dataset):\n",
    "    \n",
    "    d3 = dataset[dataset[\"activity_id\"] == 3]\n",
    "    d4 = dataset[dataset[\"activity_id\"] == 4]\n",
    "    d12 = dataset[dataset[\"activity_id\"] == 12]\n",
    "    d13 = dataset[dataset[\"activity_id\"] == 13]\n",
    "    hand = [\"imu_hand.1\",\"imu_hand.2\",\"imu_hand.3\"]\n",
    "    chest = [\"IMU_chest.1\",\"IMU_chest.2\",\"IMU_chest.3\"]\n",
    "    ancle = [\"IMU_ancle.1\",\"IMU_ancle.2\",\"IMU_ancle.3\"]\n",
    "    imuhand_3=d3[[\"time_stamp\",\"activity_id\", \"imu_hand.1\",\"imu_hand.2\",\"imu_hand.3\"]].dropna()\n",
    "    imuhand_3 = series_to_supervised(imuhand_3,hand,84)\n",
    "    imuchest_3=d3[[\"time_stamp\",\"activity_id\",\"IMU_chest.1\",\"IMU_chest.2\",\"IMU_chest.3\"]].dropna()\n",
    "    imuchest_3 = series_to_supervised(imuchest_3,chest,84)\n",
    "    imuancle_3 = d3[[\"time_stamp\",\"activity_id\",\"IMU_ancle.1\",\"IMU_ancle.2\",\"IMU_ancle.3\"]].dropna()\n",
    "    imuancle_3 = series_to_supervised(imuancle_3,ancle,84)\n",
    "\n",
    "    imuhand_4=d4[[\"time_stamp\",\"activity_id\", \"imu_hand.1\",\"imu_hand.2\",\"imu_hand.3\"]].dropna()\n",
    "    imuhand_4 = series_to_supervised(imuhand_4,hand,84)\n",
    "    imuchest_4=d4[[\"time_stamp\",\"activity_id\",\"IMU_chest.1\",\"IMU_chest.2\",\"IMU_chest.3\"]].dropna()\n",
    "    imuchest_4 = series_to_supervised(imuchest_4,chest,84)\n",
    "    imuancle_4= d4[[\"time_stamp\",\"activity_id\",\"IMU_ancle.1\",\"IMU_ancle.2\",\"IMU_ancle.3\"]].dropna()\n",
    "    imuancle_4 = series_to_supervised(imuancle_4,ancle,84)\n",
    "\n",
    "    imuhand_12=d12[[\"time_stamp\",\"activity_id\", \"imu_hand.1\",\"imu_hand.2\",\"imu_hand.3\"]].dropna()\n",
    "    imuhand_12 = series_to_supervised(imuhand_12,hand,84)\n",
    "    imuchest_12=d12[[\"time_stamp\",\"activity_id\",\"IMU_chest.1\",\"IMU_chest.2\",\"IMU_chest.3\"]].dropna()\n",
    "    imuchest_12 = series_to_supervised(imuchest_12,chest,84)\n",
    "    imuancle_12 = d12[[\"time_stamp\",\"activity_id\",\"IMU_ancle.1\",\"IMU_ancle.2\",\"IMU_ancle.3\"]].dropna()\n",
    "    imuancle_12 = series_to_supervised(imuancle_12,ancle,84)\n",
    "\n",
    "    imuhand_13=d13[[\"time_stamp\",\"activity_id\", \"imu_hand.1\",\"imu_hand.2\",\"imu_hand.3\"]].dropna()\n",
    "    imuhand_13 = series_to_supervised(imuhand_13,hand,84)\n",
    "    imuchest_13=d13[[\"time_stamp\",\"activity_id\",\"IMU_chest.1\",\"IMU_chest.2\",\"IMU_chest.3\"]].dropna()\n",
    "    imuchest_13 = series_to_supervised(imuchest_13,chest,84)\n",
    "    imuancle_13= d13[[\"time_stamp\",\"activity_id\",\"IMU_ancle.1\",\"IMU_ancle.2\",\"IMU_ancle.3\"]].dropna()\n",
    "    imuancle_13 = series_to_supervised(imuancle_13,ancle,84)\n",
    "\n",
    "    merged_hand = pd.concat([imuhand_3,imuhand_4,imuhand_12,imuhand_13],ignore_index = True)\n",
    "    merged_chest = pd.concat([imuchest_3,imuchest_4,imuchest_12,imuchest_13],ignore_index = True)\n",
    "    merged_ancle = pd.concat([imuancle_3,imuancle_4,imuancle_12,imuancle_13],ignore_index = True)\n",
    "\n",
    "    return merged_hand,merged_chest, merged_ancle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73725, 257)\n",
      "(74237, 257)\n",
      "(74271, 257)\n"
     ]
    }
   ],
   "source": [
    "sbj_1_hand, sbj_1_chest, sbj_1_ancle = get_series(subject1)\n",
    "print(sbj_1_hand.shape)\n",
    "print(sbj_1_chest.shape)\n",
    "print(sbj_1_ancle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85738, 257)\n",
      "(87212, 257)\n",
      "(86877, 257)\n"
     ]
    }
   ],
   "source": [
    "sbj_3_hand, sbj_3_chest, sbj_3_ancle = get_series(subject3)\n",
    "print(sbj_3_hand.shape)\n",
    "print(sbj_3_chest.shape)\n",
    "print(sbj_3_ancle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "sbj_3_hand = shuffle(sbj_3_hand, random_state=0)\n",
    "sbj_3_chest = shuffle(sbj_3_chest, random_state=0)\n",
    "sbj_3_ancle = shuffle(sbj_3_ancle, random_state=0)\n",
    "sbj_1_hand = shuffle(sbj_1_hand, random_state=0)\n",
    "sbj_1_chest = shuffle(sbj_1_chest, random_state=0)\n",
    "sbj_1_ancle = shuffle(sbj_1_ancle, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hand = sbj_1_hand\n",
    "\n",
    "dataset_chest = sbj_1_chest[:73725]\n",
    "\n",
    "dataset_ancle =sbj_1_ancle[:73725]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73725\n",
      "73725\n",
      "73725\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_hand))\n",
    "print(len(dataset_chest))\n",
    "print(len(dataset_ancle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(data):\n",
    "    target = data[[\"activity_id\"]]\n",
    "    data.pop(\"activity_id\")\n",
    "    return data,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chest,y_chest = data_gen(dataset_chest)\n",
    "x_hand, y_hand = data_gen(dataset_hand)\n",
    "x_ancle,y_ancle = data_gen(dataset_ancle)\n",
    "x_test_hand,y_test_hand = data_gen(sbj_3_hand)\n",
    "x_test_chest,y_test_chest = data_gen(sbj_3_chest)\n",
    "x_test_ancle,y_test_ancle = data_gen(sbj_3_ancle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87212, 256)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_chest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(data, norm_data):\n",
    "    train_stats = data.describe()\n",
    "    train_stats = train_stats.transpose()\n",
    "    return(norm_data - train_stats['mean'])/ train_stats['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_hand = x_hand.values.reshape(73725,1,256)\n",
    "\n",
    "\n",
    "x_chest = x_chest.values.reshape(73725,1,256)\n",
    "\n",
    "\n",
    "x_ancle = x_ancle.values.reshape(73725,1,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_hand = x_test_hand[:1000]\n",
    "test_hand = xtest_hand.values.reshape(1000,1,256)\n",
    "xtest_chest = x_test_chest[:1000]\n",
    "test_chest = xtest_chest.values.reshape(1000,1,256)\n",
    "xtest_ancle = x_test_ancle[:1000]\n",
    "test_ancle = xtest_ancle.values.reshape(1000,1,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_target(data):\n",
    "    cont = []\n",
    "    for i in data[\"activity_id\"]:\n",
    "        if i == 3:\n",
    "            cont.append(0)\n",
    "        elif i == 4:\n",
    "            cont.append(1)\n",
    "        elif i == 12:\n",
    "            cont.append(2)\n",
    "        elif i == 13:\n",
    "            cont.append(3)\n",
    "    data[\"activity_id\"] = cont\n",
    "    \n",
    "    return data\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_train1 =y_hand\n",
    "y_train = recode_target(y_train1)\n",
    "\n",
    "y_test1 = y_test_hand[:1000]\n",
    "y_test = recode_target(y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = data_utils.TensorDataset(torch.tensor(x_hand), torch.tensor(y_train.values))\n",
    "train_loader1 = data_utils.DataLoader(head, batch_size=1000, shuffle=False)\n",
    "head = data_utils.TensorDataset(torch.tensor(x_chest), torch.tensor(y_train.values))\n",
    "train_loader2 = data_utils.DataLoader(head, batch_size=1000, shuffle=False)\n",
    "head = data_utils.TensorDataset(torch.tensor(x_ancle), torch.tensor(y_train.values))\n",
    "train_loader3 = data_utils.DataLoader(head, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = data_utils.TensorDataset(torch.tensor(test_hand), torch.tensor(y_test.values))\n",
    "train_loader_test1 = data_utils.DataLoader(head, batch_size=1000, shuffle=False)\n",
    "head = data_utils.TensorDataset(torch.tensor(test_chest), torch.tensor(y_test.values))\n",
    "train_loader_test2 = data_utils.DataLoader(head, batch_size=1000, shuffle=False)\n",
    "head = data_utils.TensorDataset(torch.tensor(test_ancle), torch.tensor(y_test.values))\n",
    "train_loader_test3 = data_utils.DataLoader(head, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([725, 1, 256])\n",
      "tensor([[[ 5.9501e+02,  6.3400e-01,  9.7646e+00,  ...,  7.9779e-01,\n",
      "           9.7290e+00, -7.8801e-01]],\n",
      "\n",
      "        [[ 1.5885e+03,  1.8174e+00,  7.4019e+00,  ...,  4.4860e-01,\n",
      "           5.0914e+00, -1.8635e+00]],\n",
      "\n",
      "        [[ 1.8695e+03,  6.3769e-02,  4.5649e+00,  ...,  1.3717e+00,\n",
      "           1.4990e+01, -7.6483e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.6922e+02,  3.5337e-01,  9.7246e+00,  ...,  3.2107e-01,\n",
      "           9.7637e+00, -1.4550e+00]],\n",
      "\n",
      "        [[ 1.9832e+03, -8.4136e-01,  1.0365e+01,  ...,  5.7770e-01,\n",
      "           3.3257e+00, -1.1971e+00]],\n",
      "\n",
      "        [[ 2.3083e+03,  1.1770e-01,  6.2241e+00,  ...,  5.3346e-01,\n",
      "           1.3108e+01, -2.3139e+00]]], dtype=torch.float64)\n",
      "tensor([[[ 1.9372e+03,  9.7627e+00, -1.6538e+00,  ...,  9.7266e+00,\n",
      "          -1.3878e+00, -4.0948e-01]],\n",
      "\n",
      "        [[ 2.3825e+03,  2.2762e+00, -2.6981e+00,  ...,  1.0969e+01,\n",
      "           2.1005e-01, -1.7573e+00]],\n",
      "\n",
      "        [[ 6.2865e+02,  9.3503e+00, -2.6290e+00,  ...,  9.4505e+00,\n",
      "          -2.8163e+00, -1.9470e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5734e+03,  5.7237e+00,  1.3347e+01,  ..., -4.5550e-01,\n",
      "          -5.9785e+00, -2.3377e+00]],\n",
      "\n",
      "        [[ 1.8877e+03,  9.2446e-01,  2.6709e-01,  ...,  9.0770e+00,\n",
      "           3.4495e+00, -1.7968e+00]],\n",
      "\n",
      "        [[ 1.9420e+03,  2.6854e+01,  4.1948e+00,  ...,  1.3130e+01,\n",
      "           2.1764e+00, -2.4419e+00]]], dtype=torch.float64)\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "for i,(z,j,q) in enumerate(zip(train_loader1,train_loader2,train_loader3)):\n",
    "    f= i\n",
    "    (d,g) = z\n",
    "    (o,u) = j\n",
    "    (s,a) = q\n",
    "print(d.shape)\n",
    "print(o)\n",
    "print(s)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(CNN_Model, self).__init__()\n",
    "        \n",
    "        self.conv11 = nn.Conv1d(in_channels = 1, out_channels = 8, kernel_size = 5, padding=0)\n",
    "        self.pool11 = nn.AvgPool1d(kernel_size=2)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "        self.conv12 = nn.Conv1d(in_channels = 8, out_channels = 4, kernel_size = 5,padding = 0)\n",
    "        self.pool12 = nn.AvgPool1d(kernel_size = 2)\n",
    "        \n",
    "        self.conv21 = nn.Conv1d(in_channels = 1, out_channels = 8, kernel_size = 5, padding=0)\n",
    "        self.pool21 = nn.AvgPool1d(2)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "        self.conv22 = nn.Conv1d(in_channels = 8, out_channels = 4, kernel_size = 5,padding = 0)\n",
    "        self.pool22 = nn.AvgPool1d(2)\n",
    "        \n",
    "        self.conv31 = nn.Conv1d(in_channels = 1, out_channels = 8, kernel_size = 5, padding=0)\n",
    "        self.pool31 = nn.AvgPool1d(2)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "        self.conv32 = nn.Conv1d(in_channels = 8, out_channels = 4, kernel_size = 5,padding = 0)\n",
    "        self.pool32 = nn.AvgPool1d(2)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(732, 256)\n",
    "        self.fc2 = nn.Linear(256,64)\n",
    "        self.fc3 = nn.Linear(64, 4)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        in_size1 = len(x[0])\n",
    "        x1 = self.conv11(x[0])\n",
    "        x1 = self.pool11(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        x1 = self.dropout(x1)\n",
    "        x1 = F.relu(self.pool12(self.conv12(x1)))\n",
    "        x1 = x1.view(in_size1, -1)\n",
    "        \n",
    "        in_size2 = len(x[1])\n",
    "        x2 = F.relu(self.pool21(self.conv21(x[0])))\n",
    "        x2 = self.dropout(x2)\n",
    "        x2 = F.relu(self.pool22(self.conv22(x2)))\n",
    "        x2 = x2.view(in_size2, -1)\n",
    "        \n",
    "        in_size3 = len(x[2])\n",
    "        x3 = F.relu(self.pool31(self.conv31(x[0])))\n",
    "        x3 = self.dropout(x3)\n",
    "        x3 = F.relu(self.pool32(self.conv32(x3)))\n",
    "        x3 = x3.view(in_size3, -1)\n",
    "        \n",
    "        x = torch.cat((x1,x2,x3),1)\n",
    "        #print(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #print(x)\n",
    "        x = F.softmax(self.fc3(x))\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = CNN_Model()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model1 = model.double()\n",
    "    model1.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data1,data2,data3) in enumerate(zip(train_loader1,train_loader2,train_loader3)):\n",
    "        (head_data,target) = data1\n",
    "        (chest_data,target) = data2\n",
    "        (ancle_data,target) = data3\n",
    "        target = target\n",
    "        head_data, target = Var(head_data), Var(target.long())\n",
    "        \n",
    "        chest_data, target = Var(chest_data), Var(target.long())\n",
    "        \n",
    "        ancle_data, target1 = Var(ancle_data), Var(target.long())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model1(([head_data,chest_data,ancle_data]))\n",
    "        \n",
    "        target1 = target1.squeeze()\n",
    "        loss = F.nll_loss(output, target1)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss += F.nll_loss(output, target1, size_average=False).data\n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target1.data.view_as(pred)).cpu().sum()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data1), len(train_loader1.dataset),\n",
    "                100. * batch_idx / len(train_loader1), loss.item()))\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_loss /= len(train_loader_test1.dataset)\n",
    "    writer.add_scalar(\"Loss/train_loss\", train_loss,epoch)\n",
    "    print('\\nTrain_Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "         correct, len(train_loader1.dataset),\n",
    "        100. * correct / len(train_loader1.dataset)))\n",
    "    writer.add_scalar(\"Accuracy/train_accuracy\", 100. * correct / len(train_loader_test1.dataset),epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model1 = model.double()\n",
    "    model1.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data1,data2,data3) in enumerate(zip(train_loader_test1,train_loader_test2,train_loader_test3)):\n",
    "        (head_data,target) = data1\n",
    "        (chest_data,target) = data2\n",
    "        (ancle_data,target) = data3\n",
    "        target = target\n",
    "        head_data, target = Var(head_data ), Var(target.long())\n",
    "        \n",
    "        chest_data, target = Var(chest_data ), Var(target.long())\n",
    "        \n",
    "        ancle_data, target1 = Var(ancle_data), Var(target.long())\n",
    "        \n",
    "        output = model1(([head_data,chest_data,ancle_data]))\n",
    "        \n",
    "        target1 = target1.squeeze()\n",
    "        test_loss += F.nll_loss(output, target1, size_average=False).data\n",
    "        \n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target1.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(train_loader_test1.dataset)\n",
    "    writer.add_scalar(\"Loss/test_loss\",test_loss,epoch)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Test_Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(train_loader_test1.dataset),\n",
    "        100. * correct / len(train_loader_test1.dataset)))\n",
    "    writer.add_scalar(\"Accuracy/test_accuracy\", 100. * correct / len(train_loader_test1.dataset),epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/73725 (0%)]\tLoss: -0.243968\n",
      "Train Epoch: 0 [20/73725 (14%)]\tLoss: -0.250002\n",
      "Train Epoch: 0 [40/73725 (27%)]\tLoss: -0.263517\n",
      "Train Epoch: 0 [60/73725 (41%)]\tLoss: -0.287951\n",
      "Train Epoch: 0 [80/73725 (54%)]\tLoss: -0.307714\n",
      "Train Epoch: 0 [100/73725 (68%)]\tLoss: -0.310898\n",
      "Train Epoch: 0 [120/73725 (81%)]\tLoss: -0.323094\n",
      "Train Epoch: 0 [140/73725 (95%)]\tLoss: -0.330241\n",
      "\n",
      "Train_Accuracy: 20006/73725 (27%)\n",
      "\n",
      "\n",
      "Test set: Average loss: -0.3864, Test_Accuracy: 360/1000 (36%)\n",
      "\n",
      "Train Epoch: 1 [0/73725 (0%)]\tLoss: -0.334963\n",
      "Train Epoch: 1 [20/73725 (14%)]\tLoss: -0.322531\n",
      "Train Epoch: 1 [40/73725 (27%)]\tLoss: -0.319320\n",
      "Train Epoch: 1 [60/73725 (41%)]\tLoss: -0.330237\n",
      "Train Epoch: 1 [80/73725 (54%)]\tLoss: -0.329980\n",
      "Train Epoch: 1 [100/73725 (68%)]\tLoss: -0.329505\n",
      "Train Epoch: 1 [120/73725 (81%)]\tLoss: -0.336415\n",
      "Train Epoch: 1 [140/73725 (95%)]\tLoss: -0.342190\n",
      "\n",
      "Train_Accuracy: 21923/73725 (30%)\n",
      "\n",
      "\n",
      "Test set: Average loss: -0.4017, Test_Accuracy: 360/1000 (36%)\n",
      "\n",
      "Train Epoch: 2 [0/73725 (0%)]\tLoss: -0.346649\n",
      "Train Epoch: 2 [20/73725 (14%)]\tLoss: -0.339163\n",
      "Train Epoch: 2 [40/73725 (27%)]\tLoss: -0.339898\n",
      "Train Epoch: 2 [60/73725 (41%)]\tLoss: -0.342835\n",
      "Train Epoch: 2 [80/73725 (54%)]\tLoss: -0.343079\n",
      "Train Epoch: 2 [100/73725 (68%)]\tLoss: -0.345776\n",
      "Train Epoch: 2 [120/73725 (81%)]\tLoss: -0.353051\n",
      "Train Epoch: 2 [140/73725 (95%)]\tLoss: -0.355300\n",
      "\n",
      "Train_Accuracy: 22139/73725 (30%)\n",
      "\n",
      "\n",
      "Test set: Average loss: -0.4111, Test_Accuracy: 360/1000 (36%)\n",
      "\n",
      "Train Epoch: 3 [0/73725 (0%)]\tLoss: -0.357900\n",
      "Train Epoch: 3 [20/73725 (14%)]\tLoss: -0.352033\n",
      "Train Epoch: 3 [40/73725 (27%)]\tLoss: -0.349296\n",
      "Train Epoch: 3 [60/73725 (41%)]\tLoss: -0.353945\n",
      "Train Epoch: 3 [80/73725 (54%)]\tLoss: -0.348476\n",
      "Train Epoch: 3 [100/73725 (68%)]\tLoss: -0.355960\n",
      "Train Epoch: 3 [120/73725 (81%)]\tLoss: -0.371491\n",
      "Train Epoch: 3 [140/73725 (95%)]\tLoss: -0.372419\n",
      "\n",
      "Train_Accuracy: 23365/73725 (32%)\n",
      "\n",
      "\n",
      "Test set: Average loss: -0.4243, Test_Accuracy: 375/1000 (38%)\n",
      "\n",
      "Train Epoch: 4 [0/73725 (0%)]\tLoss: -0.369667\n",
      "Train Epoch: 4 [20/73725 (14%)]\tLoss: -0.375083\n",
      "Train Epoch: 4 [40/73725 (27%)]\tLoss: -0.380615\n",
      "Train Epoch: 4 [60/73725 (41%)]\tLoss: -0.383893\n",
      "Train Epoch: 4 [80/73725 (54%)]\tLoss: -0.392075\n",
      "Train Epoch: 4 [100/73725 (68%)]\tLoss: -0.404159\n",
      "Train Epoch: 4 [120/73725 (81%)]\tLoss: -0.428773\n",
      "Train Epoch: 4 [140/73725 (95%)]\tLoss: -0.439264\n",
      "\n",
      "Train_Accuracy: 32200/73725 (44%)\n",
      "\n",
      "\n",
      "Test set: Average loss: -0.4692, Test_Accuracy: 600/1000 (60%)\n",
      "\n",
      "Train Epoch: 5 [0/73725 (0%)]\tLoss: -0.431984\n",
      "Train Epoch: 5 [20/73725 (14%)]\tLoss: -0.445372\n",
      "Train Epoch: 5 [40/73725 (27%)]\tLoss: -0.459253\n",
      "Train Epoch: 5 [60/73725 (41%)]\tLoss: -0.464949\n",
      "Train Epoch: 5 [80/73725 (54%)]\tLoss: -0.466007\n",
      "Train Epoch: 5 [100/73725 (68%)]\tLoss: -0.489155\n",
      "Train Epoch: 5 [120/73725 (81%)]\tLoss: -0.502757\n",
      "Train Epoch: 5 [140/73725 (95%)]\tLoss: -0.497973\n",
      "\n",
      "Train_Accuracy: 39829/73725 (54%)\n",
      "\n",
      "\n",
      "Test set: Average loss: -0.5469, Test_Accuracy: 652/1000 (65%)\n",
      "\n",
      "Train Epoch: 6 [0/73725 (0%)]\tLoss: -0.487684\n",
      "Train Epoch: 6 [20/73725 (14%)]\tLoss: -0.508957\n",
      "Train Epoch: 6 [40/73725 (27%)]\tLoss: -0.509894\n",
      "Train Epoch: 6 [60/73725 (41%)]\tLoss: -0.511294\n",
      "Train Epoch: 6 [80/73725 (54%)]\tLoss: -0.510765\n",
      "Train Epoch: 6 [100/73725 (68%)]\tLoss: -0.534830\n",
      "Train Epoch: 6 [120/73725 (81%)]\tLoss: -0.539743\n",
      "Train Epoch: 6 [140/73725 (95%)]\tLoss: -0.530632\n",
      "\n",
      "Train_Accuracy: 41417/73725 (56%)\n",
      "\n",
      "\n",
      "Test set: Average loss: -0.5837, Test_Accuracy: 644/1000 (64%)\n",
      "\n",
      "Train Epoch: 7 [0/73725 (0%)]\tLoss: -0.519370\n",
      "Train Epoch: 7 [20/73725 (14%)]\tLoss: -0.543682\n",
      "Train Epoch: 7 [40/73725 (27%)]\tLoss: -0.546391\n",
      "Train Epoch: 7 [60/73725 (41%)]\tLoss: -0.532186\n",
      "Train Epoch: 7 [80/73725 (54%)]\tLoss: -0.532353\n",
      "Train Epoch: 7 [100/73725 (68%)]\tLoss: -0.557322\n",
      "Train Epoch: 7 [120/73725 (81%)]\tLoss: -0.556084\n",
      "Train Epoch: 7 [140/73725 (95%)]\tLoss: -0.551561\n",
      "\n",
      "Train_Accuracy: 41666/73725 (57%)\n",
      "\n",
      "\n",
      "Test set: Average loss: -0.6016, Test_Accuracy: 643/1000 (64%)\n",
      "\n",
      "Train Epoch: 8 [0/73725 (0%)]\tLoss: -0.530530\n",
      "Train Epoch: 8 [20/73725 (14%)]\tLoss: -0.549587\n",
      "Train Epoch: 8 [40/73725 (27%)]\tLoss: -0.556266\n",
      "Train Epoch: 8 [60/73725 (41%)]\tLoss: -0.542270\n",
      "Train Epoch: 8 [80/73725 (54%)]\tLoss: -0.539874\n",
      "Train Epoch: 8 [100/73725 (68%)]\tLoss: -0.561737\n",
      "Train Epoch: 8 [120/73725 (81%)]\tLoss: -0.575741\n",
      "Train Epoch: 8 [140/73725 (95%)]\tLoss: -0.566199\n",
      "\n",
      "Train_Accuracy: 41862/73725 (57%)\n",
      "\n",
      "\n",
      "Test set: Average loss: -0.6034, Test_Accuracy: 639/1000 (64%)\n",
      "\n",
      "Train Epoch: 9 [0/73725 (0%)]\tLoss: -0.546421\n",
      "Train Epoch: 9 [20/73725 (14%)]\tLoss: -0.557244\n",
      "Train Epoch: 9 [40/73725 (27%)]\tLoss: -0.561419\n",
      "Train Epoch: 9 [60/73725 (41%)]\tLoss: -0.550116\n",
      "Train Epoch: 9 [80/73725 (54%)]\tLoss: -0.550255\n",
      "Train Epoch: 9 [100/73725 (68%)]\tLoss: -0.569016\n",
      "Train Epoch: 9 [120/73725 (81%)]\tLoss: -0.580707\n",
      "Train Epoch: 9 [140/73725 (95%)]\tLoss: -0.566926\n",
      "\n",
      "Train_Accuracy: 42064/73725 (57%)\n",
      "\n",
      "\n",
      "Test set: Average loss: -0.5830, Test_Accuracy: 633/1000 (63%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
